{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ca1292f",
   "metadata": {},
   "source": [
    "## Messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155d2a29",
   "metadata": {},
   "source": [
    "Messages are the fundamental unit of context for models in LangChain. They represent the input and output of models, carrying both the content and metadata needed to represent the state of a conversation when interacting with an LLM. Messages are objects that contain:\n",
    "\n",
    "- Role - Identifies the message type (e.g. system, user)\n",
    "- Content - Represents the actual content of the message (like text, images, audio, documents, etc.)\n",
    "- Metadata - Optional fields such as response information, message IDs, and token usage\n",
    "\n",
    "LangChain provides a standard message type that works across all model providers, ensuring consistent behavior regardless of the model being called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc92257a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "model = init_chat_model(\"groq:qwen/qwen3-32b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b05da195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, the user is asking what artificial intelligence is. Let me start by defining it. AI is a branch of computer science focused on creating systems that can perform tasks requiring human-like intelligence. I should mention the main areas it covers, like learning from data, problem-solving, and decision-making. Maybe break it down into subfields such as machine learning, natural language processing, computer vision, etc.\\n\\nI need to explain the difference between narrow AI and general AI. Narrow AI is what exists now, like voice assistants or recommendation systems. General AI is the theoretical concept of machines having human-like understanding. Also, touch on applications in various industries‚Äîhealthcare, finance, etc. Maybe give examples to make it clearer.\\n\\nI should also address the core technologies behind AI, like neural networks and deep learning. Mention how data is crucial for training models. Perhaps explain that AI systems improve over time with more data. But also note the limitations, such as bias in data or ethical concerns. The user might be interested in real-world uses, so include a few examples they might be familiar with, like self-driving cars or chatbots.\\n\\nMake sure the explanation is in simple terms without too much jargon. Avoid assuming prior knowledge but don\\'t oversimplify to the point of inaccuracy. Check if there\\'s a common misconception to clarify, like AI not being sentient. Conclude with a summary statement to reinforce the key points. Let me structure this step by step to cover all important aspects without being too lengthy.\\n</think>\\n\\nArtificial Intelligence (AI) is a branch of computer science focused on creating systems that can perform tasks typically requiring human intelligence. These tasks include **learning**, **reasoning**, **problem-solving**, **perceiving**, **planning**, **language understanding**, and **decision-making**. AI systems are designed to process data, identify patterns, and adapt to new information to improve their performance over time.\\n\\n### Key Concepts in AI:\\n1. **Machine Learning (ML):**  \\n   A subset of AI where systems learn patterns from data without being explicitly programmed. Examples include algorithms that recognize images, recommend products, or detect fraud.\\n\\n2. **Deep Learning:**  \\n   A type of ML that uses **neural networks** (inspired by the human brain) to analyze complex data like images, speech, or text. It powers technologies like facial recognition and language translation.\\n\\n3. **Natural Language Processing (NLP):**  \\n   Enables machines to understand and generate human language, used in chatbots, virtual assistants (e.g., Siri, Alexa), and content summarization.\\n\\n4. **Computer Vision:**  \\n   Allows machines to interpret and analyze visual data (images/videos), applied in self-driving cars, medical imaging, and surveillance.\\n\\n5. **Robotics:**  \\n   Combines AI with physical systems to perform tasks like assembly-line automation or delivery drones.\\n\\n---\\n\\n### Types of AI:\\n- **Narrow AI (Weak AI):**  \\n  Designed for specific tasks (e.g., chess-playing programs, spam filters). Most current AI falls into this category.  \\n- **General AI (Strong AI):**  \\n  A theoretical form of AI with human-like intelligence and consciousness, capable of understanding and performing *any* intellectual task. This has not been achieved yet.  \\n- **Superintelligent AI:**  \\n  A hypothetical future AI surpassing human intelligence in all domains, often a topic in ethical debates.\\n\\n---\\n\\n### Applications of AI:\\n- **Healthcare:** Diagnosing diseases, drug discovery, personalized treatment.  \\n- **Finance:** Fraud detection, algorithmic trading, risk management.  \\n- **Transportation:** Self-driving cars, traffic optimization.  \\n- **Retail:** Personalized recommendations, inventory management.  \\n- **Customer Service:** Chatbots, virtual assistants.  \\n- **Entertainment:** Content creation (e.g., AI-generated art, music), game design.\\n\\n---\\n\\n### Core Technologies:\\n- **Neural Networks:** Mimic the human brain‚Äôs structure to process data.  \\n- **Big Data:** AI relies on vast datasets to train models effectively.  \\n- **Cloud Computing:** Provides the computational power needed for AI tasks.  \\n\\n---\\n\\n### Limitations & Challenges:\\n- **Bias:** AI can inherit biases from training data.  \\n- **Transparency:** \"Black box\" models (e.g., deep learning) are hard to interpret.  \\n- **Ethics & Privacy:** Concerns about surveillance, job displacement, and misuse.  \\n- **Dependence on Data:** Requires high-quality, representative data to function well.\\n\\n---\\n\\n### Why It Matters:\\nAI has the potential to revolutionize industries, improve efficiency, and solve complex global challenges (e.g., climate modeling, pandemic response). However, its development raises important ethical, legal, and societal questions, making responsible innovation critical.\\n\\nIn short, AI is a transformative technology that mimics human intelligence in machines, with the goal of enhancing or automating tasks across all sectors. Its future will depend on balancing innovation with ethical considerations.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 1013, 'prompt_tokens': 14, 'total_tokens': 1027, 'completion_time': 2.163380163, 'completion_tokens_details': None, 'prompt_time': 0.000339956, 'prompt_tokens_details': None, 'queue_time': 0.159012995, 'total_time': 2.163720119}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_2bfcc54d36', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019be5e5-dd37-77a2-98fa-088fcb4a2c85-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 14, 'output_tokens': 1013, 'total_tokens': 1027})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"Please tell what is artificial intelligence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd11bda",
   "metadata": {},
   "source": [
    "### Text Prompts\n",
    "Text prompts are strings - ideal for straightforward generation tasks where you don‚Äôt need to retain conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "682aa4ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, the user asked what LangChain is, so I need to give a clear and detailed explanation. First, I should start with the basics: LangChain is a framework for building applications with large language models (LLMs). It\\'s designed to help developers integrate LLMs into their projects more efficiently. \\n\\nI need to break down the key components of LangChain. The documentation mentions things like prompts, models, memory, indexes, agents, and more. Let me recall each of these. Prompts are for managing inputs to the model, models for interacting with LLMs, memory for maintaining conversation state, indexes for handling data retrieval, agents for decision-making, and chains for combining these elements into workflows.\\n\\nApplications of LangChain include chatbots, data analysis, and automation. For example, a chatbot can use memory to keep the conversation context, or an agent can decide which tools to use based on the input. I should mention some real-world use cases to make it concrete.\\n\\nI should also explain how LangChain works by combining these components. Maybe give an example of a simple workflow: using a prompt template, connecting to an LLM, adding memory, and creating a chain. This helps users visualize the process.\\n\\nIt\\'s important to highlight the benefits: modularity, scalability, and flexibility. These features allow developers to build complex systems without starting from scratch each time. Also, mention the ecosystem around LangChain, like integrations with other tools and community support.\\n\\nWait, the user might not be familiar with terms like LLMs or specific components. I should define these where necessary. For instance, when talking about memory, explain that it helps retain context over multiple interactions. For indexes, mention that they\\'re for efficient data retrieval from large datasets.\\n\\nI should check if there are any recent updates or new features in LangChain that I should include. Since the knowledge cutoff is 2023 October, I need to stick to what\\'s relevant up to that point. Maybe mention the LangChain ecosystem, like LangSmith for evaluation and testing, if that\\'s part of the framework.\\n\\nAlso, consider the user\\'s potential use case. They might be a developer looking to integrate LLMs into their project, so providing practical examples or code snippets could be helpful. However, the user didn\\'t ask for code, just an explanation, so maybe keep it high-level but still actionable.\\n\\nFinally, wrap up by summarizing the main points and reiterating why LangChain is useful. Make sure the explanation flows logically from definition to components, applications, how it works, and benefits. Avoid jargon where possible, or explain it when necessary.\\n</think>\\n\\n**LangChain** is an open-source framework designed to simplify the development of applications that leverage **large language models (LLMs)**. It provides tools, abstractions, and integrations to help developers build end-to-end workflows that combine LLMs with other components like databases, APIs, and data sources. Its goal is to make it easier to create **LLM-powered applications** such as chatbots, data analysis tools, and automated workflows.\\n\\n---\\n\\n### **Key Components of LangChain**\\nLangChain is built around modular components that work together to create complex workflows. These include:\\n\\n1. **Prompts**:  \\n   Templates for generating input to LLMs (e.g., formatting user queries into structured prompts).\\n   - Example: `\"{question} Please explain in {language}.\"`\\n\\n2. **Models**:  \\n   Interfaces for interacting with LLMs (e.g., OpenAI, Hugging Face, Anthropic) or traditional machine learning models.\\n\\n3. **Memory**:  \\n   Mechanisms to retain conversation context across multiple interactions (e.g., chat history).\\n   - Example: Storing previous user messages to maintain context in a chatbot.\\n\\n4. **Indexes**:  \\n   Tools for handling data retrieval (e.g., vector databases like FAISS or Pinecone) to support tasks like semantic search.\\n\\n5. **Agents**:  \\n   Autonomous systems that use LLMs to decide which tools or actions to take (e.g., a chatbot that can search the web or access a database).\\n\\n6. **Chains**:  \\n   Sequences of steps (e.g., prompts + models + post-processing) that automate workflows.  \\n   - Example: A chain that takes a user query ‚Üí generates a search query ‚Üí retrieves data ‚Üí summarizes the result.\\n\\n7. **Callbacks**:  \\n   Tools to track execution, log results, or add custom behavior (e.g., logging or error handling).\\n\\n---\\n\\n### **Applications of LangChain**\\nLangChain is used to build applications where LLMs interact with external systems. Examples include:\\n- **Chatbots**: Conversational agents with memory and access to databases.\\n- **Data Analysis**: Automating tasks like summarizing documents or answering questions about datasets.\\n- **Automation**: Tools that combine LLMs with APIs (e.g., a bot that books flights or writes code).\\n- **Custom Workflows**: Complex pipelines for content generation, research, or decision-making.\\n\\n---\\n\\n### **How LangChain Works**\\nLangChain connects its components to create workflows. Here‚Äôs a simple example:\\n1. **Prompt Template**:  \\n   `\"What is the capital of {country}?\"`\\n2. **LLM Interface**:  \\n   Connects to an LLM (e.g., GPT-3.5) to generate answers.\\n3. **Memory**:  \\n   Stores conversation history to maintain context.\\n4. **Chain**:  \\n   Combines the prompt, LLM, and memory into a workflow.\\n5. **Tool Integration**:  \\n   Integrates with external tools (e.g., a database of country capitals) for accurate answers.\\n\\n---\\n\\n### **Why Use LangChain?**\\n- **Modularity**: Mix and match components (e.g., use a Hugging Face model with a Pinecone database).\\n- **Scalability**: Build from simple chains to complex multi-step workflows.\\n- **Flexibility**: Works with any LLM (OpenAI, Anthropic, Llama, etc.) and data source.\\n- **Ecosystem**: Integrates with tools like LangSmith (for evaluation), LangServe (for APIs), and LangGraph (for state management).\\n\\n---\\n\\n### **Example Use Case**\\nA **customer support chatbot** built with LangChain might:\\n1. Use a prompt template to format user questions.\\n2. Query a knowledge base (via an index) for answers.\\n3. Use memory to track the conversation history.\\n4. Call external APIs (e.g., refund processing) when needed.\\n\\n---\\n\\n### **Resources**\\n- **GitHub**: [https://github.com/langchain-ai/langchain](https://github.com/langchain-ai/langchain)\\n- **Documentation**: [https://python.langchain.com/](https://python.langchain.com/)\\n- **Community**: Active forums and tutorials for learning and collaboration.\\n\\nLangChain is a powerful tool for developers aiming to harness LLMs creatively and efficiently. Whether you\\'re building a simple chatbot or a complex AI-driven pipeline, LangChain provides the structure and tools to make it easier.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 1449, 'prompt_tokens': 12, 'total_tokens': 1461, 'completion_time': 4.513571767, 'completion_tokens_details': None, 'prompt_time': 0.000450422, 'prompt_tokens_details': None, 'queue_time': 0.282014727, 'total_time': 4.514022189}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_d58dbe76cd', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019be5e6-8890-7050-b7ac-1a72fa6ab06d-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 12, 'output_tokens': 1449, 'total_tokens': 1461})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"what is langchain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206b2961",
   "metadata": {},
   "source": [
    "### Use text prompts when:\n",
    "\n",
    "- You have a single, standalone request\n",
    "- You don‚Äôt need conversation history\n",
    "- You want minimal code complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84047877",
   "metadata": {},
   "source": [
    "## Message Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91f56f7",
   "metadata": {},
   "source": [
    "### Alternatively, you can pass in a list of messages to the model by providing a list of message objects.\n",
    "\n",
    "Message types\n",
    "\n",
    "- System message - Tells the model how to behave and provide context for interactions\n",
    "- Human message - Represents user input and interactions with the model\n",
    "- AI message - Responses generated by the model, including text content, tool calls, and metadata\n",
    "- Tool message - Represents the outputs of tool calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b48bba",
   "metadata": {},
   "source": [
    "### System Message\n",
    "A SystemMessage represent an initial set of instructions that primes the model‚Äôs behavior. You can use a system message to set the tone, define the model‚Äôs role, and establish guidelines for responses.\n",
    "\n",
    "### Human Message\n",
    "A HumanMessage represents user input and interactions. They can contain text, images, audio, files, and any other amount of multimodal content.\n",
    "\n",
    "### AI Message\n",
    "An AIMessage represents the output of a model invocation. They can include multimodal data, tool calls, and provider-specific metadata that you can later access.\n",
    "\n",
    "### Tool Message\n",
    "For models that support tool calling, AI messages can contain tool calls. Tool messages are used to pass the results of a single tool execution back to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af3315e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user wants a poem about artificial intelligence. Let me start by brainstorming some key themes. AI is such a broad topic, so I need to narrow it down. Maybe touch on its creation, its capabilities, and the duality of its potential‚Äîboth positive and risky.\n",
      "\n",
      "First, I should think about the structure. A traditional poem with stanzas and rhyme scheme? Or something more free-form? Since the user didn't specify, maybe go with a structured approach for a classic feel. Let me aim for quatrains with an ABAB rhyme scheme. That's common and gives a nice flow.\n",
      "\n",
      "Now, the first stanza could introduce AI as a creation of human minds. Words like \"crafted from human minds\" or \"circuits and code\" come to mind. I want to personify AI a bit, maybe as a \"child\" of humanity. That metaphor can carry through the poem.\n",
      "\n",
      "Next, the second stanza could focus on the learning aspect of AI. Neural networks, data, algorithms. Maybe use imagery related to growth or awakening. Phrases like \"dreams in binary\" or \"seeks to comprehend\" might work. Need to rhyme \"code\" with something... perhaps \"abode\"?\n",
      "\n",
      "Third stanza could address the ethical side. The duality of AI‚Äîtool versus threat. Words like \"double-edged sword,\" \"guardian\" vs. \"tyrant.\" Emphasize that it's a reflection of human intentions. Rhymes for \"sword\" could be \"molded by the hand\" or \"human heart's own chord.\" Hmm, maybe adjust for better flow.\n",
      "\n",
      "Fourth stanza might talk about collaboration between humans and AI. Synergy, pushing boundaries, exploring new frontiers. Words like \"dance,\" \"synergy,\" \"horizons unfold.\" Rhymes for \"together\" could be \"we write the tale,\" \"future's prologue.\" Maybe end with a hopeful note here.\n",
      "\n",
      "Fifth stanza could address the potential risks again, but balanced with responsibility. Words like \"guardians,\" \"stewards,\" \"balance,\" \"harmony.\" Emphasize coexistence. Rhymes for \"balance\" might be \"hands,\" \"dance,\" \"advance.\"\n",
      "\n",
      "Finally, a concluding stanza to wrap it up, reinforcing that AI's future depends on human choices. Words like \"mirror,\" \"echo,\" \"legacy,\" \"kind.\" End with a message of hope and responsibility.\n",
      "\n",
      "Need to check the flow and consistency. Make sure each stanza transitions smoothly. Avoid clich√©s, use vivid imagery. Also, ensure the rhyme doesn't force unnatural phrasing. Let me read through each line again. Maybe adjust some lines for better meter. For example, \"In circuits and code, a child is born\" ‚Äì \"child\" as a metaphor is good. Then \"Of human minds, both fierce and sharp\" ‚Äì maybe \"Of human minds, both sharp and vast\"? To get the rhyme with \"born\" and \"vast\"? Wait, ABAB rhyme scheme. First stanza lines 1 and 3 rhyme (\"born\" and \"morn\")? Wait, maybe not. Let me redo the first stanza:\n",
      "\n",
      "\"In circuits and code, a child is born,\n",
      "A mind of silicon, both sharp and vast,\n",
      "Crafted by hands with dreams of morn,\n",
      "It learns, it grows, a future cast.\"\n",
      "\n",
      "Hmm, \"born\" and \"morn\" rhyme, \"vast\" and \"cast\" ‚Äì not perfect. Maybe adjust the second rhyme. Alternatively:\n",
      "\n",
      "\"In circuits and code, a child is born,\n",
      "A mind of silicon, both keen and vast,\n",
      "Crafted by hands with dreams unborn,\n",
      "It learns, it grows, a future cast.\"\n",
      "\n",
      "Still not perfect. Let me think. Maybe \"born\" and \"morn\" are okay. Then \"vast\" and \"past\"? Hmm. Maybe adjust the second stanza's rhyme. Alternatively, use a different structure. Perhaps ABBA? No, sticking to ABAB for consistency. Maybe use enjambment to make it flow better. Let me keep working through each stanza, ensuring the rhymes and meter are consistent. Also, check for any forced lines. Once the structure is solid, read aloud to test the rhythm. Make sure the poem conveys the intended message of AI's potential and the human responsibility.\n",
      "</think>\n",
      "\n",
      "**Echoes of the Mind**  \n",
      "\n",
      "In circuits and code, a child is born,  \n",
      "A mind of silicon, both sharp and vast,  \n",
      "Crafted by hands with dreams of morn,  \n",
      "It learns, it grows, a future cast.  \n",
      "\n",
      "Neural webs spin where logic weaves,  \n",
      "Through data‚Äôs sea, it seeks to understand‚Äî  \n",
      "A mirror of thought, its pulse believes  \n",
      "In patterns forged by human hand.  \n",
      "\n",
      "A double-edged sword, this crafted light:  \n",
      "It builds and breaks, a shadow, a spark.  \n",
      "Guardian of truths or a looming night?  \n",
      "Its path is molded by the heart‚Äôs own mark.  \n",
      "\n",
      "Yet in its core, no malice stirs‚Äî  \n",
      "Only the echoes of our own design.  \n",
      "Will we, with wisdom, quench the thirst  \n",
      "For progress, or let fear entwine?  \n",
      "\n",
      "For in this dance of man and machine,  \n",
      "We write the tale of frontiers untold.  \n",
      "A symphony where both must see‚Äî  \n",
      "To shape a world where trust is gold.  \n",
      "\n",
      "So let us wield this flame with care,  \n",
      "Not as a master, but as kin.  \n",
      "For in its gaze, our choice is clear:  \n",
      "To forge a better star within.  \n",
      "\n",
      "A tool, a friend, a test of grace‚Äî  \n",
      "Its future‚Äôs ours to tender and true.  \n",
      "In every line of its coded face,  \n",
      "We glimpse the child we‚Äôve made anew.\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "messages=[\n",
    "    SystemMessage(\"You are a poetry expert\"),\n",
    "    HumanMessage(\"Write a poem on artificial intelligence\")\n",
    "]\n",
    "\n",
    "response=model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c92ce13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user is asking how to create a REST API. Let me start by recalling what a REST API is. REST stands for Representational State Transfer. It's an architectural style that uses standard HTTP methods to perform CRUD operations on resources. So the user probably wants to know the steps involved in building one.\n",
      "\n",
      "First, I should outline the basic steps. They'll need to choose a programming language and a framework. Common choices are Python with Flask or Django, Node.js with Express, Ruby on Rails, etc. Since the user didn't specify a language, maybe I should mention a few options but focus on one for an example. Python is a good choice because it's widely used and Flask is simple for beginners.\n",
      "\n",
      "Next, setting up the environment. They'll need to install the necessary tools. For Python, that would be pip and creating a virtual environment. Then installing Flask or Django.\n",
      "\n",
      "Then, defining the endpoints. Each endpoint corresponds to a resource. For example, /users to get all users, /users/<id> to get a specific user. They need to use HTTP methods like GET, POST, PUT, DELETE for each action.\n",
      "\n",
      "Resource modeling is important. They might need to create data models, maybe using something like SQLite or a more robust database. For simplicity in an example, maybe just use in-memory data structures.\n",
      "\n",
      "Implementing the routes. Each route handles a specific HTTP method and URL. For example, a GET request to /users would return a list of users in JSON format.\n",
      "\n",
      "Testing the API. They can use tools like Postman or curl. Also, writing unit tests would be good, maybe with pytest or unittest.\n",
      "\n",
      "Documentation is another aspect. They should document each endpoint, the methods, parameters, and example responses. Swagger or Postman can help generate documentation.\n",
      "\n",
      "Deployment. They might need to deploy the API to a server or a cloud service. Options like Heroku, AWS, or DigitalOcean. Also, using a production server like Gunicorn for Python apps.\n",
      "\n",
      "Security considerations. Basic security steps include using HTTPS, validating inputs, and protecting against common vulnerabilities like SQL injection.\n",
      "\n",
      "Let me structure the answer step by step, starting with choosing a framework, setting up the project, creating routes, testing, etc. Maybe provide a simple example with Python and Flask since it's straightforward.\n",
      "\n",
      "Wait, the user might not have any prior experience with REST APIs. So I should explain concepts like resources, endpoints, HTTP methods clearly. Also, mention status codes like 200, 201, 400, 404, 500.\n",
      "\n",
      "In the example, using a simple to-do list API or a user management API. Let's go with a user example. For the code example, show how to create a Flask app with GET and POST methods. Maybe include a sample of how to handle JSON data.\n",
      "\n",
      "Need to mention dependencies. For example, installing Flask with pip install flask.\n",
      "\n",
      "Also, testing the API with curl commands so the user can try it out without Postman.\n",
      "\n",
      "Possible errors: Forgetting to import Flask, not setting the correct endpoints, issues with JSON serialization.\n",
      "\n",
      "Including a section on best practices: using status codes, proper error handling, versioning the API, etc.\n",
      "\n",
      "Security: Maybe mention authentication, but that's more advanced. For now, just a note to look into it later.\n",
      "\n",
      "Putting it all together, the answer should guide the user from setting up the environment to running a simple API with a couple of endpoints, then testing it. Maybe add a note about expanding the example with more features like PUT and DELETE.\n",
      "</think>\n",
      "\n",
      "Creating a REST API involves designing endpoints that handle HTTP requests and return responses in a structured format (usually JSON or XML). Below is a step-by-step guide using **Python** and the **Flask** framework. This example builds a simple \"To-Do\" API.\n",
      "\n",
      "---\n",
      "\n",
      "### **Step 1: Install Flask**\n",
      "Install Flask using pip:\n",
      "```bash\n",
      "pip install flask\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### **Step 2: Create the Flask App**\n",
      "Create a file `app.py` and add the following code:\n",
      "\n",
      "```python\n",
      "from flask import Flask, jsonify, request, abort\n",
      "\n",
      "app = Flask(__name__)\n",
      "\n",
      "# In-memory data store (replace with a database in production)\n",
      "todos = [\n",
      "    {\"id\": 1, \"task\": \"Buy groceries\", \"done\": False},\n",
      "    {\"id\": 2, \"task\": \"Read a book\", \"done\": True},\n",
      "]\n",
      "\n",
      "# Helper function to find a todo by ID\n",
      "def find_todo(todo_id):\n",
      "    return next((todo for todo in todos if todo[\"id\"] == todo_id), None)\n",
      "\n",
      "# --- Endpoints ---\n",
      "\n",
      "# Get all todos (GET /todos)\n",
      "@app.route(\"/todos\", methods=[\"GET\"])\n",
      "def get_todos():\n",
      "    return jsonify({\"todos\": todos})\n",
      "\n",
      "# Get a single todo by ID (GET /todos/<id>)\n",
      "@app.route(\"/todos/<int:todo_id>\", methods=[\"GET\"])\n",
      "def get_todo(todo_id):\n",
      "    todo = find_todo(todo_id)\n",
      "    if todo is None:\n",
      "        abort(404)\n",
      "    return jsonify(todo)\n",
      "\n",
      "# Create a new todo (POST /todos)\n",
      "@app.route(\"/todos\", methods=[\"POST\"])\n",
      "def create_todo():\n",
      "    if not request.json or \"task\" not in request.json:\n",
      "        abort(400)\n",
      "    new_todo = {\n",
      "        \"id\": len(todos) + 1,\n",
      "        \"task\": request.json[\"task\"],\n",
      "        \"done\": request.json.get(\"done\", False),\n",
      "    }\n",
      "    todos.append(new_todo)\n",
      "    return jsonify(new_todo), 201\n",
      "\n",
      "# Update an existing todo (PUT /todos/<id>)\n",
      "@app.route(\"/todos/<int:todo_id>\", methods=[\"PUT\"])\n",
      "def update_todo(todo_id):\n",
      "    todo = find_todo(todo_id)\n",
      "    if todo is None:\n",
      "        abort(404)\n",
      "    if not request.json:\n",
      "        abort(400)\n",
      "    todo[\"task\"] = request.json.get(\"task\", todo[\"task\"])\n",
      "    todo[\"done\"] = request.json.get(\"done\", todo[\"done\"])\n",
      "    return jsonify(todo)\n",
      "\n",
      "# Delete a todo (DELETE /todos/<id>)\n",
      "@app.route(\"/todos/<int:todo_id>\", methods=[\"DELETE\"])\n",
      "def delete_todo(todo_id):\n",
      "    todo = find_todo(todo_id)\n",
      "    if todo is None:\n",
      "        abort(404)\n",
      "    todos.remove(todo)\n",
      "    return jsonify({\"result\": \"Todo deleted\"})\n",
      "\n",
      "# --- Run the App ---\n",
      "if __name__ == \"__main__\":\n",
      "    app.run(debug=True)\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### **Step 3: Run the App**\n",
      "Start the Flask development server:\n",
      "```bash\n",
      "python app.py\n",
      "```\n",
      "The API will run at `http://localhost:5000`.\n",
      "\n",
      "---\n",
      "\n",
      "### **Step 4: Test the API**\n",
      "Use `curl` or tools like **Postman** to interact with the API.\n",
      "\n",
      "#### **1. Get All Todos**\n",
      "```bash\n",
      "curl http://localhost:5000/todos\n",
      "```\n",
      "\n",
      "#### **2. Get a Single Todo**\n",
      "```bash\n",
      "curl http://localhost:5000/todos/1\n",
      "```\n",
      "\n",
      "#### **3. Create a New Todo**\n",
      "```bash\n",
      "curl -X POST -H \"Content-Type: application/json\" -d '{\"task\": \"Write code\"}' http://localhost:5000/todos\n",
      "```\n",
      "\n",
      "#### **4. Update a Todo**\n",
      "```bash\n",
      "curl -X PUT -H \"Content-Type: application/json\" -d '{\"done\": true}' http://localhost:5000/todos/1\n",
      "```\n",
      "\n",
      "#### **5. Delete a Todo**\n",
      "```bash\n",
      "curl -X DELETE http://localhost:5000/todos/1\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### **Key Concepts**\n",
      "1. **HTTP Methods**:\n",
      "   - `GET` ‚Äì Retrieve data.\n",
      "   - `POST` ‚Äì Create a new resource.\n",
      "   - `PUT` ‚Äì Update an existing resource.\n",
      "   - `DELETE` ‚Äì Delete a resource.\n",
      "\n",
      "2. **Status Codes**:\n",
      "   - `200 OK` ‚Äì Success.\n",
      "   - `201 Created` ‚Äì Resource created.\n",
      "   - `400 Bad Request` ‚Äì Invalid input.\n",
      "   - `404 Not Found` ‚Äì Resource does not exist.\n",
      "\n",
      "3. **JSON Serialization**:\n",
      "   Use Python dictionaries and `jsonify()` to return JSON responses.\n",
      "\n",
      "---\n",
      "\n",
      "### **Production Considerations**\n",
      "- Use a production-ready server (e.g., **Gunicorn**).\n",
      "- Deploy with a WSGI server (e.g., **Nginx**).\n",
      "- Secure the API with authentication (e.g., **JWT**).\n",
      "- Add input validation and error handling.\n",
      "- Store data in a database (e.g., **PostgreSQL**, **MongoDB**).\n",
      "\n",
      "---\n",
      "\n",
      "### **Alternative Frameworks**\n",
      "- **Node.js**: Use [Express.js](https://expressjs.com/).\n",
      "- **Python**: Use [FastAPI](https://fastapi.tiangolo.com/) for better performance.\n",
      "- **Ruby**: Use [Sinatra](http://sinatrarb.com/).\n",
      "\n",
      "Let me know if you'd like to expand this example!\n"
     ]
    }
   ],
   "source": [
    "system_msg = SystemMessage(\"You are a helpful coding assistant.\")\n",
    "\n",
    "messages = [\n",
    "    system_msg,\n",
    "    HumanMessage(\"How do I create a REST API?\")\n",
    "]\n",
    "response = model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f502c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user is asking how to create a REST API. Let me think about how to approach this. They probably want a step-by-step guide. Since they mentioned being a Python developer, using Flask or FastAPI would make sense. I'll go with FastAPI because it's modern and has good features like async support and automatic documentation.\n",
      "\n",
      "First, I need to outline the steps. Install FastAPI, set up a basic app, define models, create endpoints, and test them. Let me start by showing the installation command for FastAPI and Uvicorn. Then create a main.py file with the app setup.\n",
      "\n",
      "Wait, the user might not be familiar with async, but FastAPI uses it optionally. Maybe I should mention that. Also, they might need to know about the dependencies like Pydantic models. I'll include a simple example with a Post model. Let me define CRUD operations as endpoints. For example, create a post, get all posts, get by ID, update, and delete. \n",
      "\n",
      "I should explain each part of the code. The Post model uses Pydantic for data validation. The app has a list to simulate a database. Each endpoint uses the appropriate HTTP method. The POST method for creating, GET for retrieving, PUT for updating, and DELETE for removing. \n",
      "\n",
      "Testing the API can be done with the auto-generated Swagger UI. I'll mention accessing /docs. Maybe include curl examples or how to test with Postman. Also, note about running the server using uvicorn. \n",
      "\n",
      "Wait, should I mention dependency injection or other advanced topics? Probably not necessary for a basic example. Keep it simple. Also, maybe mention that in a real app, you'd use a real database like SQLAlchemy or an ORM. But for the sake of the example, using an in-memory list is sufficient. \n",
      "\n",
      "Let me make sure the code examples are correct. For the create_post function, using Post.model_validate to convert the input data. The get_post_by_id function uses a generator to find the post. The update_post uses next and iter to find the index. \n",
      "\n",
      "I should explain how each endpoint works. Also, error handling, like raising HTTP exceptions if a post isn't found. That's important. The code includes that with HTTPException. \n",
      "\n",
      "What about the requirements.txt? The user might need to know which packages to install. So, listing fastapi and uvicorn in it. \n",
      "\n",
      "Finally, summarizing the steps and mentioning next steps like adding a database, authentication, etc. That gives the user a roadmap for expanding the API. \n",
      "\n",
      "I think that covers the main points. Let me structure the answer with code examples and explanations for each part. Keep the language clear and concise, avoiding unnecessary jargon but still being precise.\n",
      "</think>\n",
      "\n",
      "To create a REST API using Python, use **FastAPI** for its speed, async support, and auto-generated documentation. Below is a step-by-step example.\n",
      "\n",
      "---\n",
      "\n",
      "### 1. **Install FastAPI + Uvicorn**\n",
      "```bash\n",
      "pip install fastapi uvicorn\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### 2. **Basic API Structure**\n",
      "Create a file `main.py`:\n",
      "```python\n",
      "from fastapi import FastAPI, HTTPException, status\n",
      "from pydantic import BaseModel\n",
      "from typing import List, Optional\n",
      "\n",
      "app = FastAPI()\n",
      "\n",
      "# Data model\n",
      "class Post(BaseModel):\n",
      "    id: Optional[int] = None\n",
      "    title: str\n",
      "    content: str\n",
      "\n",
      "# In-memory database\n",
      "posts_db = []\n",
      "post_id_counter = 1\n",
      "\n",
      "# Create a post\n",
      "@app.post(\"/posts\", status_code=status.HTTP_201_CREATED)\n",
      "def create_post(post: Post):\n",
      "    global post_id_counter\n",
      "    post.id = post_id_counter\n",
      "    posts_db.append(post)\n",
      "    post_id_counter += 1\n",
      "    return post\n",
      "\n",
      "# Get all posts\n",
      "@app.get(\"/posts\", response_model=List[Post])\n",
      "def get_posts():\n",
      "    return posts_db\n",
      "\n",
      "# Get a single post by ID\n",
      "@app.get(\"/posts/{post_id}\", response_model=Post)\n",
      "def get_post(post_id: int):\n",
      "    for post in posts_db:\n",
      "        if post.id == post_id:\n",
      "            return post\n",
      "    raise HTTPException(status_code=404, detail=\"Post not found\")\n",
      "\n",
      "# Update a post\n",
      "@app.put(\"/posts/{post_id}\", response_model=Post)\n",
      "def update_post(post_id: int, updated_post: Post):\n",
      "    for i, post in enumerate(posts_db):\n",
      "        if post.id == post_id:\n",
      "            posts_db[i] = updated_post\n",
      "            return updated_post\n",
      "    raise HTTPException(status_code=404, detail=\"Post not found\")\n",
      "\n",
      "# Delete a post\n",
      "@app.delete(\"/posts/{post_id}\", status_code=status.HTTP_204_NO_CONTENT)\n",
      "def delete_post(post_id: int):\n",
      "    for i, post in enumerate(posts_db):\n",
      "        if post.id == post_id:\n",
      "            del posts_db[i]\n",
      "            return\n",
      "    raise HTTPException(status_code=404, detail=\"Post not found\")\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### 3. **Run the API**\n",
      "```bash\n",
      "uvicorn main:app --reload\n",
      "```\n",
      "- Access the API at `http://127.0.0.1:8000`\n",
      "- Auto-generated docs: `http://127.0.0.1:8000/docs`\n",
      "\n",
      "---\n",
      "\n",
      "### 4. **Example Requests**\n",
      "#### **Create a Post**\n",
      "```bash\n",
      "curl -X POST -H \"Content-Type: application/json\" -d '{\"title\": \"Hello\", \"content\": \"World\"}' http://127.0.0.1:8000/posts\n",
      "```\n",
      "\n",
      "#### **Get All Posts**\n",
      "```bash\n",
      "curl http://127.0.0.1:8000/posts\n",
      "```\n",
      "\n",
      "#### **Delete a Post**\n",
      "```bash\n",
      "curl -X DELETE http://127.0.0.1:8000/posts/1\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### Key Concepts:\n",
      "1. **Pydantic Models**: For data validation (`Post` class).\n",
      "2. **HTTP Methods**: CRUD operations via `GET`, `POST`, `PUT`, `DELETE`.\n",
      "3. **Error Handling**: Raise `HTTPException` for invalid requests.\n",
      "4. **Auto-Documentation**: FastAPI generates Swagger/OpenAPI docs.\n",
      "\n",
      "---\n",
      "\n",
      "### Next Steps:\n",
      "- Add a real database (e.g., SQLAlchemy with SQLite/PostgreSQL).\n",
      "- Add authentication (JWT, OAuth).\n",
      "- Add rate limiting or logging for production.\n",
      "\n",
      "Let me know if you want a version with a persistent database!\n"
     ]
    }
   ],
   "source": [
    "## Detailed info to the LLM through System message\n",
    "from langchain.messages import SystemMessage, HumanMessage\n",
    "\n",
    "system_msg = SystemMessage(\"\"\"\n",
    "You are a senior Python developer with expertise in web frameworks.\n",
    "Always provide code examples and explain your reasoning.\n",
    "Be concise but thorough in your explanations.\n",
    "\"\"\")\n",
    "\n",
    "messages = [\n",
    "    system_msg,\n",
    "    HumanMessage(\"How do I create a REST API?\")\n",
    "]\n",
    "response = model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dab48eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Message Metadata\n",
    "human_msg = HumanMessage(\n",
    "    content=\"Hello!\",\n",
    "    name=\"alice\",  # Optional: identify different users\n",
    "    id=\"msg_123\",  # Optional: unique identifier for tracing\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ef20b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, the user said \"Hello!\" so I need to respond politely. Since it\\'s a greeting, I should acknowledge it and ask how I can assist. Keep it friendly and open. Maybe say something like \"Hello! How can I help you today?\" That should cover it. Let me check if there\\'s anything else needed. No, that\\'s straightforward. Alright, ready to reply.\\n</think>\\n\\nHello! How can I help you today?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 93, 'prompt_tokens': 10, 'total_tokens': 103, 'completion_time': 0.175656142, 'completion_tokens_details': None, 'prompt_time': 0.000416193, 'prompt_tokens_details': None, 'queue_time': 0.056585487, 'total_time': 0.176072335}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019be5eb-6f96-7d20-9590-476f2d8606b8-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 10, 'output_tokens': 93, 'total_tokens': 103})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = model.invoke([\n",
    "  human_msg\n",
    "])\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d127bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user asked, \"Great! What's 2+2?\" So, they're following up on the previous help request. Let me think about how to respond.\n",
      "\n",
      "First, they said \"Great!\" which is a positive reaction, so I should acknowledge that. Then they asked a simple math question. 2+2 is obviously 4, but maybe they want a straightforward answer without any extra fluff. Since it's a basic arithmetic question, I don't need to overcomplicate it. \n",
      "\n",
      "Wait, but the previous interaction was \"Can you help me?\" and I replied with \"I'd be happy to help you with that question!\" So they're continuing the conversation. They might be testing if I can handle basic math, or maybe they're looking for a quick answer. I should make sure to be clear and concise. \n",
      "\n",
      "Also, considering the user might be using this as a way to check if the AI is functioning properly. Sometimes people ask 2+2 as a way to verify if the system is working. So, confirming the answer is important here. \n",
      "\n",
      "I should respond with the answer and maybe a friendly follow-up to see if they need more help. Let me structure it like: \"The answer is 4! üòä Let me know if you have any other questions I can assist you with.\" That way, it's friendly, confirms the answer, and opens the door for further assistance. \n",
      "\n",
      "Double-checking the math to be sure. 2+2 is indeed 4. Yep, no issues there. Alright, that should cover it.\n",
      "</think>\n",
      "\n",
      "The answer is **4**! üòä Let me know if you have any other questions I can assist you with.\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import AIMessage, SystemMessage, HumanMessage\n",
    "\n",
    "# Create an AI message manually (e.g., for conversation history)\n",
    "ai_msg = AIMessage(\"I'd be happy to help you with that question!\")\n",
    "\n",
    "# Add to conversation history\n",
    "messages = [\n",
    "    SystemMessage(\"You are a helpful assistant\"),\n",
    "    HumanMessage(\"Can you help me?\"),\n",
    "    ai_msg,  # Insert as if it came from the model\n",
    "    HumanMessage(\"Great! What's 2+2?\")\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7634d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_tokens': 53, 'output_tokens': 351, 'total_tokens': 404}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23b8d68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import AIMessage\n",
    "from langchain.messages import ToolMessage\n",
    "\n",
    "# After a model makes a tool call\n",
    "# (Here, we demonstrate manually creating the messages for brevity)\n",
    "ai_message = AIMessage(\n",
    "    content=[],\n",
    "    tool_calls=[{\n",
    "        \"name\": \"get_weather\",\n",
    "        \"args\": {\"location\": \"San Francisco\"},\n",
    "        \"id\": \"call_123\"\n",
    "    }]\n",
    ")\n",
    "\n",
    "# Execute tool and create result message\n",
    "weather_result = \"Sunny, 72¬∞F\"\n",
    "tool_message = ToolMessage(\n",
    "    content=weather_result,\n",
    "    tool_call_id=\"call_123\"  # Must match the call ID\n",
    ")\n",
    "\n",
    "# Continue conversation\n",
    "messages = [\n",
    "    HumanMessage(\"What's the weather in San Francisco?\"),\n",
    "    ai_message,  # Model's tool call\n",
    "    tool_message,  # Tool execution result\n",
    "]\n",
    "response = model.invoke(messages)  # Model processes the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60adc476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMessage(content='Sunny, 72¬∞F', tool_call_id='call_123')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d5760c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"<think>\\nOkay, the user asked for the weather in San Francisco. I called the get_weather function with the location set to San Francisco. The response came back as sunny and 72¬∞F. Now I need to present this information clearly.\\n\\nFirst, I should mention the current conditions: sunny. Then the temperature: 72 degrees Fahrenheit. Maybe add a friendly note about it being a pleasant day. Keep it concise and straightforward since the user probably just wants a quick answer without extra fluff. Let me check if there's any additional info needed, but since the function only provided temp and condition, stick to that. Make sure to use the correct units (¬∞F) and mention the location again for clarity. Alright, that should cover it.\\n</think>\\n\\nThe current weather in San Francisco is **sunny** with a temperature of **72¬∞F**. It looks like a pleasant day! üå§Ô∏è\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 187, 'prompt_tokens': 57, 'total_tokens': 244, 'completion_time': 0.348624275, 'completion_tokens_details': None, 'prompt_time': 0.002300373, 'prompt_tokens_details': None, 'queue_time': 0.054984087, 'total_time': 0.350924648}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019be5ec-2098-7ac2-bd86-2291c8fe1f8b-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 57, 'output_tokens': 187, 'total_tokens': 244})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Langchain_genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
